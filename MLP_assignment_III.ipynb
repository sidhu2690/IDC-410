{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOssXHFurYbLTgiuPWlzdWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidhu2690/IDC-410/blob/main/MLP_assignment_III.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKzsmpymzrGN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdpAJ0ke0ZlY",
        "outputId": "25d16a51-0741-4b44-ce47-7e40c4c7b529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "replace mnist_train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        next(file)\n",
        "        for line in file:\n",
        "            values = line.strip().split(',')\n",
        "            label = float(values[0])\n",
        "            image = [float(val) / 255.0 for val in values[1:]]\n",
        "            y_data.append(label)\n",
        "            x_data.append(image)\n",
        "    x = np.array(x_data)\n",
        "    y = np.array(y_data)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "B3QGAjdRz2RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = load_data('/content/mnist_train.csv')\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", Y.shape)"
      ],
      "metadata": {
        "id": "4URpbizgzwfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d7bb51-0456-4643-cd6f-3030c6763e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (60000, 784)\n",
            "y shape: (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=np.random.randint(1,60000)\n",
        "plt.imshow(X[i].reshape(28,28))\n",
        "print(f\"The number is {int(Y[i])}\")"
      ],
      "metadata": {
        "id": "mrmoiXmi0Gw4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "55d5a1ba-d7c5-4298-db4e-fe00764ac864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number is 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.1)"
      ],
      "metadata": {
        "id": "9XT7meeU3FyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "def initialize_parameters(input_size, output_size):\n",
        "    W = np.random.randn(input_size, output_size) / np.sqrt(input_size)\n",
        "    b = np.zeros((1, output_size))\n",
        "    return W, b\n",
        "\n",
        "def forward_pass(X, W, b):\n",
        "    Z = np.dot(X, W) + b\n",
        "    return Z, softmax(Z)\n",
        "\n",
        "def backward_pass(X, y, Z, A, W, b, learning_rate):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    dZ = A - y\n",
        "    dW = np.dot(X.T, dZ) / m\n",
        "    db = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "\n",
        "    W -= learning_rate * dW\n",
        "    b -= learning_rate * db\n",
        "\n",
        "    return W, b\n",
        "\n",
        "def train_model(X, y, num_classes, learning_rate, epochs):\n",
        "    input_size = X.shape[1]\n",
        "    W, b = initialize_parameters(input_size, num_classes)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        Z, A = forward_pass(X, W, b)\n",
        "        W, b = backward_pass(X, y, Z, A, W, b, learning_rate)\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            loss = -np.mean(np.log(A[np.arange(len(y)), np.argmax(y, axis=1)]))\n",
        "            print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "    return W, b"
      ],
      "metadata": {
        "id": "B4Ftn5IC2foE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encoding"
      ],
      "metadata": {
        "id": "FCDi9UOu3oRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.astype(np.int64)\n",
        "y_train_one_hot = np.zeros((y_train.size, 10))\n",
        "y_train_one_hot[np.arange(y_train.size), y_train] = 1\n",
        "y_test = y_test.astype(np.int64)\n",
        "y_one_hot_1 = np.zeros((y_test.size, 10))\n",
        "y_one_hot_1[np.arange(y_test.size), y_test] = 1"
      ],
      "metadata": {
        "id": "G6QyyocE26mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 250\n",
        "num_classes = 10\n",
        "\n",
        "# Train the model\n",
        "W, b = train_model(x_train, y_train_one_hot, num_classes, learning_rate, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maQU4AOd3ebf",
        "outputId": "ae5a7767-b900-4799-a280-a3f00722d69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.325209765387293\n",
            "Epoch 50, Loss: 1.8600461516365303\n",
            "Epoch 100, Loss: 1.5609887469215382\n",
            "Epoch 150, Loss: 1.3517451656164472\n",
            "Epoch 200, Loss: 1.2020076437757354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, W, b):\n",
        "    _, A = forward_pass(X, W, b)\n",
        "    return np.argmax(A, axis=1)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "y_pred = predict(x_test, W, b)\n",
        "y_true = np.argmax(y_one_hot_1, axis=1)\n",
        "acc = accuracy(y_true, y_pred)\n",
        "print(\"Accuracy:\", acc*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um7GtrkL3Sb7",
        "outputId": "1c629cde-191a-4979-d1a4-6a87160a53e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=np.random.randint(1,12000)\n",
        "print(f\"predicted number\",predict(x_test[i],W,b))\n",
        "plt.imshow(x_test[i].reshape(28,28))"
      ],
      "metadata": {
        "id": "_PQWA8Dt9dM3",
        "outputId": "03ba5499-c7ae-4e6d-d720-1e4bcc6c70e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted number [2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e8df54265c0>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3"
      ],
      "metadata": {
        "id": "QYdSPAKK62OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    W1 = np.random.randn(input_size, hidden_size) / np.sqrt(input_size)\n",
        "    b1 = np.zeros((1, hidden_size))\n",
        "    W2 = np.random.randn(hidden_size, output_size) / np.sqrt(hidden_size)\n",
        "    b2 = np.zeros((1, output_size))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def forward_pass(X, W1, b1, W2, b2):\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    A1 = sigmoid(Z1)       #sigmoid activation\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    A2 = softmax(Z2)\n",
        "    return Z1, A1, Z2, A2\n",
        "\n",
        "def backward_pass(X, y, Z1, A1, Z2, A2, W1, b1, W2, b2, learning_rate):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    dZ2 = A2 - y\n",
        "    dW2 = np.dot(A1.T, dZ2) / m\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "    dA1 = np.dot(dZ2, W2.T)\n",
        "    dZ1 = dA1 * (A1 * (1 - A1))\n",
        "    dW1 = np.dot(X.T, dZ1) / m\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    correct_predictions = np.sum(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
        "    total_samples = y_true.shape[0]\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return accuracy\n",
        "\n",
        "def train_model(X, y, hidden_size, num_classes, learning_rate, epochs):\n",
        "    input_size = X.shape[1]\n",
        "    W1, b1, W2, b2 = initialize_parameters(input_size, hidden_size, num_classes)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        Z1, A1, Z2, A2 = forward_pass(X, W1, b1, W2, b2)\n",
        "        W1, b1, W2, b2 = backward_pass(X, y, Z1, A1, Z2, A2, W1, b1, W2, b2, learning_rate)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            loss = -np.mean(np.log(A2[np.arange(len(y)), np.argmax(y, axis=1)]))\n",
        "            accuracy = calculate_accuracy(y, A2)\n",
        "            print(f'Epoch {epoch}, Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "\n",
        "hidden_size = 10\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "trained_parameters = train_model(x_train, y_train_one_hot, hidden_size, num_classes, learning_rate, epochs)"
      ],
      "metadata": {
        "id": "smMtcg60AXWH",
        "outputId": "10f0eb22-62ea-4c51-a1dc-7e28cfa208d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.3954378623965042, Accuracy: 0.08402083333333334\n",
            "Epoch 10, Loss: 2.2162501531174508, Accuracy: 0.21095833333333333\n",
            "Epoch 20, Loss: 2.129585304954302, Accuracy: 0.3697916666666667\n",
            "Epoch 30, Loss: 2.050401596886019, Accuracy: 0.43533333333333335\n",
            "Epoch 40, Loss: 1.9738065876188922, Accuracy: 0.48945833333333333\n",
            "Epoch 50, Loss: 1.8991502057834275, Accuracy: 0.53475\n",
            "Epoch 60, Loss: 1.8262189933222528, Accuracy: 0.5710416666666667\n",
            "Epoch 70, Loss: 1.7552097471115369, Accuracy: 0.5993958333333333\n",
            "Epoch 80, Loss: 1.6865645709135284, Accuracy: 0.6246041666666666\n",
            "Epoch 90, Loss: 1.6207314907822847, Accuracy: 0.6463958333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "def initialize_parameters(input_size, hidden_size1, hidden_size2, output_size):\n",
        "    W1 = np.random.randn(input_size, hidden_size1) / np.sqrt(input_size)\n",
        "    b1 = np.zeros((1, hidden_size1))\n",
        "    W2 = np.random.randn(hidden_size1, hidden_size2) / np.sqrt(hidden_size1)\n",
        "    b2 = np.zeros((1, hidden_size2))\n",
        "    W3 = np.random.randn(hidden_size2, output_size) / np.sqrt(hidden_size2)\n",
        "    b3 = np.zeros((1, output_size))\n",
        "    return W1, b1, W2, b2, W3, b3\n",
        "\n",
        "def forward_pass(X, W1, b1, W2, b2, W3, b3):\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    Z3 = np.dot(A2, W3) + b3\n",
        "    A3 = softmax(Z3)\n",
        "    return Z1, A1, Z2, A2, Z3, A3\n",
        "\n",
        "def backward_pass(X, y, Z1, A1, Z2, A2, Z3, A3, W1, b1, W2, b2, W3, b3, learning_rate):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    dZ3 = A3 - y\n",
        "    dW3 = np.dot(A2.T, dZ3) / m\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
        "\n",
        "    dA2 = np.dot(dZ3, W3.T)\n",
        "    dZ2 = dA2 * (A2 * (1 - A2))\n",
        "    dW2 = np.dot(A1.T, dZ2) / m\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "    dA1 = np.dot(dZ2, W2.T)\n",
        "    dZ1 = dA1 * (A1 * (1 - A1))\n",
        "    dW1 = np.dot(X.T, dZ1) / m\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "    W3 -= learning_rate * dW3\n",
        "    b3 -= learning_rate * db3\n",
        "\n",
        "    return W1, b1, W2, b2, W3, b3\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    correct_predictions = np.sum(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
        "    total_samples = y_true.shape[0]\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return accuracy\n",
        "\n",
        "def train_model(X, y, hidden_size1, hidden_size2, num_classes, learning_rate, epochs):\n",
        "    input_size = X.shape[1]\n",
        "    W1, b1, W2, b2, W3, b3 = initialize_parameters(input_size, hidden_size1, hidden_size2, num_classes)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        Z1, A1, Z2, A2, Z3, A3 = forward_pass(X, W1, b1, W2, b2, W3, b3)\n",
        "        W1, b1, W2, b2, W3, b3 = backward_pass(X, y, Z1, A1, Z2, A2, Z3, A3, W1, b1, W2, b2, W3, b3, learning_rate)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            loss = -np.mean(np.log(A3[np.arange(len(y)), np.argmax(y, axis=1)]))\n",
        "            accuracy = calculate_accuracy(y, A3)\n",
        "            print(f'Epoch {epoch}, Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "    return W1, b1, W2, b2, W3, b3\n",
        "\n",
        "hidden_size1 = 10\n",
        "hidden_size2 = 10\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "trained_parameters = train_model(x_train, y_train_one_hot, hidden_size1, hidden_size2, num_classes, learning_rate, epochs)\n"
      ],
      "metadata": {
        "id": "46sWSt1j-hSx",
        "outputId": "e254e423-5bd7-40f4-f723-743e40c09ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.4447408933519603, Accuracy: 0.09045833333333334\n",
            "Epoch 10, Loss: 2.3019210186183474, Accuracy: 0.1455\n",
            "Epoch 20, Loss: 2.28233735194819, Accuracy: 0.12633333333333333\n",
            "Epoch 30, Loss: 2.271423046123819, Accuracy: 0.16110416666666666\n",
            "Epoch 40, Loss: 2.260333745352481, Accuracy: 0.22995833333333332\n",
            "Epoch 50, Loss: 2.2478737279791146, Accuracy: 0.2992708333333333\n",
            "Epoch 60, Loss: 2.2336158149919196, Accuracy: 0.36052083333333335\n",
            "Epoch 70, Loss: 2.217205314509312, Accuracy: 0.40475\n",
            "Epoch 80, Loss: 2.198273503894581, Accuracy: 0.4289375\n",
            "Epoch 90, Loss: 2.17644363916371, Accuracy: 0.4415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Hidden layer with ReLu"
      ],
      "metadata": {
        "id": "IJp9EZLR92_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    W1 = np.random.randn(input_size, hidden_size) / np.sqrt(input_size)\n",
        "    b1 = np.zeros((1, hidden_size))\n",
        "    W2 = np.random.randn(hidden_size, output_size) / np.sqrt(hidden_size)\n",
        "    b2 = np.zeros((1, output_size))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def forward_pass(X, W1, b1, W2, b2):\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    A2 = softmax(Z2)\n",
        "    return Z1, A1, Z2, A2\n",
        "\n",
        "def backward_pass(X, y, Z1, A1, Z2, A2, W1, b1, W2, b2, learning_rate):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    dZ2 = A2 - y\n",
        "    dW2 = np.dot(A1.T, dZ2) / m\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "    dA1 = np.dot(dZ2, W2.T)\n",
        "    dZ1 = dA1 * (Z1 > 0)\n",
        "    dW1 = np.dot(X.T, dZ1) / m\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    correct_predictions = np.sum(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
        "    total_samples = y_true.shape[0]\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return accuracy\n",
        "\n",
        "def train_model(X, y, hidden_size, num_classes, learning_rate, epochs):\n",
        "    input_size = X.shape[1]\n",
        "    W1, b1, W2, b2 = initialize_parameters(input_size, hidden_size, num_classes)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        Z1, A1, Z2, A2 = forward_pass(X, W1, b1, W2, b2)\n",
        "        W1, b1, W2, b2 = backward_pass(X, y, Z1, A1, Z2, A2, W1, b1, W2, b2, learning_rate)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            loss = -np.mean(np.log(A2[np.arange(len(y)), np.argmax(y, axis=1)]))\n",
        "            accuracy = calculate_accuracy(y, A2)\n",
        "            print(f'Epoch {epoch}, Loss: {loss}, Accuracy: {accuracy*100}')\n",
        "\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "\n",
        "hidden_size = 10\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "trained_parameters = train_model(x_train, y_train_one_hot, hidden_size, num_classes, learning_rate, epochs)\n"
      ],
      "metadata": {
        "id": "hn-_TQC86OEh",
        "outputId": "4ddb678f-ee3f-4cb3-8065-15e48e589353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.310338137763086, Accuracy: 7.88125\n",
            "Epoch 10, Loss: 1.947530267387898, Accuracy: 38.514583333333334\n",
            "Epoch 20, Loss: 1.5908829820590873, Accuracy: 52.43333333333333\n",
            "Epoch 30, Loss: 1.3154980462562567, Accuracy: 63.5\n",
            "Epoch 40, Loss: 1.109542023659461, Accuracy: 72.78958333333333\n",
            "Epoch 50, Loss: 0.9556980844574191, Accuracy: 77.25208333333333\n",
            "Epoch 60, Loss: 0.8412411728273637, Accuracy: 79.54791666666667\n",
            "Epoch 70, Loss: 0.7577206846012914, Accuracy: 81.26875\n",
            "Epoch 80, Loss: 0.6955566260823677, Accuracy: 82.51041666666666\n",
            "Epoch 90, Loss: 0.6478550874518055, Accuracy: 83.55416666666666\n",
            "Epoch 100, Loss: 0.6101884864418082, Accuracy: 84.35000000000001\n",
            "Epoch 110, Loss: 0.5796813823143224, Accuracy: 84.98333333333333\n",
            "Epoch 120, Loss: 0.5544433036093293, Accuracy: 85.53333333333333\n",
            "Epoch 130, Loss: 0.5331846892343701, Accuracy: 85.96041666666666\n",
            "Epoch 140, Loss: 0.5150265969082579, Accuracy: 86.33541666666666\n",
            "Epoch 150, Loss: 0.49931494431882373, Accuracy: 86.69583333333334\n",
            "Epoch 160, Loss: 0.485577575249812, Accuracy: 87.04375\n",
            "Epoch 170, Loss: 0.4734448899521007, Accuracy: 87.37291666666667\n",
            "Epoch 180, Loss: 0.46262998546000356, Accuracy: 87.60208333333334\n",
            "Epoch 190, Loss: 0.4529193616212346, Accuracy: 87.82083333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 Hidden layer with ReLu"
      ],
      "metadata": {
        "id": "-yldY5Vm_v7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "def initialize_parameters(input_size, hidden_size1, hidden_size2, output_size):\n",
        "    W1 = np.random.randn(input_size, hidden_size1) / np.sqrt(input_size)\n",
        "    b1 = np.zeros((1, hidden_size1))\n",
        "    W2 = np.random.randn(hidden_size1, hidden_size2) / np.sqrt(hidden_size1)\n",
        "    b2 = np.zeros((1, hidden_size2))\n",
        "    W3 = np.random.randn(hidden_size2, output_size) / np.sqrt(hidden_size2)\n",
        "    b3 = np.zeros((1, output_size))\n",
        "    return W1, b1, W2, b2, W3, b3\n",
        "\n",
        "def forward_pass(X, W1, b1, W2, b2, W3, b3):\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    A2 = relu(Z2)\n",
        "    Z3 = np.dot(A2, W3) + b3\n",
        "    A3 = softmax(Z3)\n",
        "    return Z1, A1, Z2, A2, Z3, A3\n",
        "\n",
        "def backward_pass(X, y, Z1, A1, Z2, A2, Z3, A3, W1, b1, W2, b2, W3, b3, learning_rate):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    dZ3 = A3 - y\n",
        "    dW3 = np.dot(A2.T, dZ3) / m\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
        "\n",
        "    dA2 = np.dot(dZ3, W3.T)\n",
        "    dZ2 = dA2 * (Z2 > 0)\n",
        "    dW2 = np.dot(A1.T, dZ2) / m\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "    dA1 = np.dot(dZ2, W2.T)\n",
        "    dZ1 = dA1 * (Z1 > 0)\n",
        "    dW1 = np.dot(X.T, dZ1) / m\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "    W3 -= learning_rate * dW3\n",
        "    b3 -= learning_rate * db3\n",
        "\n",
        "    return W1, b1, W2, b2, W3, b3\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    correct_predictions = np.sum(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
        "    total_samples = y_true.shape[0]\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return accuracy\n",
        "\n",
        "def train_model(X, y, hidden_size1, hidden_size2, num_classes, learning_rate, epochs):\n",
        "    input_size = X.shape[1]\n",
        "    W1, b1, W2, b2, W3, b3 = initialize_parameters(input_size, hidden_size1, hidden_size2, num_classes)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        Z1, A1, Z2, A2, Z3, A3 = forward_pass(X, W1, b1, W2, b2, W3, b3)\n",
        "        W1, b1, W2, b2, W3, b3 = backward_pass(X, y, Z1, A1, Z2, A2, Z3, A3, W1, b1, W2, b2, W3, b3, learning_rate)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            loss = -np.mean(np.log(A3[np.arange(len(y)), np.argmax(y, axis=1)]))\n",
        "            accuracy = calculate_accuracy(y, A3)\n",
        "            print(f'Epoch {epoch}, Loss: {loss}, Accuracy: {accuracy*100}')\n",
        "\n",
        "    return W1, b1, W2, b2, W3, b3\n",
        "\n",
        "hidden_size1 = 10\n",
        "hidden_size2 = 10\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "trained_parameters = train_model(x_train, y_train_one_hot, hidden_size1, hidden_size2, num_classes, learning_rate, epochs)\n"
      ],
      "metadata": {
        "id": "Pdm6sIck7oZV",
        "outputId": "916da128-80f3-4504-bbdc-dc3923fbad1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.381043203225201, Accuracy: 10.172916666666666\n",
            "Epoch 10, Loss: 2.1670522147433906, Accuracy: 14.620833333333334\n",
            "Epoch 20, Loss: 2.0021441112649088, Accuracy: 21.7\n",
            "Epoch 30, Loss: 1.8465779712115598, Accuracy: 37.56666666666666\n",
            "Epoch 40, Loss: 1.663747959694357, Accuracy: 47.989583333333336\n",
            "Epoch 50, Loss: 1.452319581998155, Accuracy: 55.21458333333334\n",
            "Epoch 60, Loss: 1.2435914087487896, Accuracy: 62.02916666666667\n",
            "Epoch 70, Loss: 1.077550590885921, Accuracy: 68.3125\n",
            "Epoch 80, Loss: 0.9607229879989333, Accuracy: 71.28750000000001\n",
            "Epoch 90, Loss: 0.8783030003618892, Accuracy: 73.20625\n",
            "Epoch 100, Loss: 0.8171438895245101, Accuracy: 74.81666666666666\n",
            "Epoch 110, Loss: 0.7687012137310532, Accuracy: 76.27083333333333\n",
            "Epoch 120, Loss: 0.7284946387942346, Accuracy: 77.6625\n",
            "Epoch 130, Loss: 0.7088022085998301, Accuracy: 78.21249999999999\n",
            "Epoch 140, Loss: 0.79210319947216, Accuracy: 74.00625\n",
            "Epoch 150, Loss: 0.6417680648088961, Accuracy: 80.52916666666667\n",
            "Epoch 160, Loss: 0.6142319039628046, Accuracy: 81.68125\n",
            "Epoch 170, Loss: 0.5913962305736636, Accuracy: 82.53541666666668\n",
            "Epoch 180, Loss: 0.5711445758185738, Accuracy: 83.19375\n",
            "Epoch 190, Loss: 0.5530285975086725, Accuracy: 83.77916666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V\n",
        "#### gd with momentum"
      ],
      "metadata": {
        "id": "Z8-jOh2s_-yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "def initialize_parameters(input_size, hidden_size1, hidden_size2, output_size):\n",
        "    W1 = np.random.randn(input_size, hidden_size1) / np.sqrt(input_size)\n",
        "    b1 = np.zeros((1, hidden_size1))\n",
        "    W2 = np.random.randn(hidden_size1, hidden_size2) / np.sqrt(hidden_size1)\n",
        "    b2 = np.zeros((1, hidden_size2))\n",
        "    W3 = np.random.randn(hidden_size2, output_size) / np.sqrt(hidden_size2)\n",
        "    b3 = np.zeros((1, output_size))\n",
        "    return W1, b1, W2, b2, W3, b3\n",
        "\n",
        "def forward_pass(X, W1, b1, W2, b2, W3, b3):\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    A2 = relu(Z2)\n",
        "    Z3 = np.dot(A2, W3) + b3\n",
        "    A3 = softmax(Z3)\n",
        "    return Z1, A1, Z2, A2, Z3, A3\n",
        "\n",
        "def backward_pass(X, y, Z1, A1, Z2, A2, Z3, A3, W1, b1, W2, b2, W3, b3, learning_rate, momentum):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    dZ3 = A3 - y\n",
        "    dW3 = np.dot(A2.T, dZ3) / m\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
        "\n",
        "    dA2 = np.dot(dZ3, W3.T)\n",
        "    dZ2 = dA2 * (Z2 > 0)\n",
        "    dW2 = np.dot(A1.T, dZ2) / m\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "    dA1 = np.dot(dZ2, W2.T)\n",
        "    dZ1 = dA1 * (Z1 > 0)\n",
        "    dW1 = np.dot(X.T, dZ1) / m\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "    # Momentum\n",
        "    if 'VdW1' not in globals():\n",
        "        VdW1 = np.zeros_like(W1)\n",
        "        Vdb1 = np.zeros_like(b1)\n",
        "        VdW2 = np.zeros_like(W2)\n",
        "        Vdb2 = np.zeros_like(b2)\n",
        "        VdW3 = np.zeros_like(W3)\n",
        "        Vdb3 = np.zeros_like(b3)\n",
        "\n",
        "    VdW3 = momentum * VdW3 - learning_rate * dW3\n",
        "    Vdb3 = momentum * Vdb3 - learning_rate * db3\n",
        "    VdW2 = momentum * VdW2 - learning_rate * dW2\n",
        "    Vdb2 = momentum * Vdb2 - learning_rate * db2\n",
        "    VdW1 = momentum * VdW1 - learning_rate * dW1\n",
        "    Vdb1 = momentum * Vdb1 - learning_rate * db1\n",
        "\n",
        "    W1 += VdW1\n",
        "    b1 += Vdb1\n",
        "    W2 += VdW2\n",
        "    b2 += Vdb2\n",
        "    W3 += VdW3\n",
        "    b3 += Vdb3\n",
        "\n",
        "    return W1, b1, W2, b2, W3, b3\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    correct_predictions = np.sum(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
        "    total_samples = y_true.shape[0]\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return accuracy\n",
        "\n",
        "def train_model(X, y, hidden_size1, hidden_size2, num_classes, learning_rate, epochs, momentum):\n",
        "    input_size = X.shape[1]\n",
        "    W1, b1, W2, b2, W3, b3 = initialize_parameters(input_size, hidden_size1, hidden_size2, num_classes)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        Z1, A1, Z2, A2, Z3, A3 = forward_pass(X, W1, b1, W2, b2, W3, b3)\n",
        "        W1, b1, W2, b2, W3, b3 = backward_pass(X, y, Z1, A1, Z2, A2, Z3, A3, W1, b1, W2, b2, W3, b3, learning_rate, momentum)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            loss = -np.mean(np.log(A3[np.arange(len(y)), np.argmax(y, axis=1)]))\n",
        "            accuracy = calculate_accuracy(y, A3)\n",
        "            print(f'Epoch {epoch}, Loss: {loss}, Accuracy: {accuracy*100}')\n",
        "\n",
        "    return W1, b1, W2, b2, W3, b3\n",
        "\n",
        "hidden_size1 = 10\n",
        "hidden_size2 = 10\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "momentum = 0.1\n",
        "\n",
        "trained_parameters = train_model(x_train, y_train_one_hot, hidden_size1, hidden_size2, num_classes, learning_rate, epochs, momentum)"
      ],
      "metadata": {
        "id": "CxfdY09Q_jZZ",
        "outputId": "6f709bc8-303b-42e8-c176-d57013d1bacf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.299345247253505, Accuracy: 11.295833333333333\n",
            "Epoch 10, Loss: 2.2041144772190036, Accuracy: 24.058333333333334\n",
            "Epoch 20, Loss: 2.0822070048887173, Accuracy: 27.89375\n",
            "Epoch 30, Loss: 1.93622853233075, Accuracy: 31.683333333333337\n",
            "Epoch 40, Loss: 1.7794096321497563, Accuracy: 36.27708333333333\n",
            "Epoch 50, Loss: 1.6224318227354424, Accuracy: 42.4875\n",
            "Epoch 60, Loss: 1.4656017612105061, Accuracy: 49.27708333333333\n",
            "Epoch 70, Loss: 1.3107360647779496, Accuracy: 62.33541666666667\n",
            "Epoch 80, Loss: 1.1749825925874533, Accuracy: 67.39375\n",
            "Epoch 90, Loss: 1.063348717418282, Accuracy: 69.69375\n",
            "Epoch 100, Loss: 0.9712084603696991, Accuracy: 71.8\n",
            "Epoch 110, Loss: 0.8944768195182846, Accuracy: 73.81875\n",
            "Epoch 120, Loss: 1.0728235699854982, Accuracy: 62.391666666666666\n",
            "Epoch 130, Loss: 0.7987141848615595, Accuracy: 76.61875\n",
            "Epoch 140, Loss: 0.7318648430054, Accuracy: 79.01041666666667\n",
            "Epoch 150, Loss: 0.6919904892343345, Accuracy: 80.45833333333333\n",
            "Epoch 160, Loss: 0.661829377760372, Accuracy: 81.16041666666666\n",
            "Epoch 170, Loss: 0.6312108810976871, Accuracy: 82.04583333333333\n",
            "Epoch 180, Loss: 0.6016329915593935, Accuracy: 83.07708333333333\n",
            "Epoch 190, Loss: 0.5778983014921701, Accuracy: 83.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4PIzo1iAKTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}